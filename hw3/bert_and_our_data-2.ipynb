{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_and_our_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2aAcef__FZO",
        "outputId": "43f26c43-02f9-4fbf-d9dd-e01552b77620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbJoL7Bh_b1A",
        "outputId": "63684370-d7a4-4f9e-9a49-e20912ef8d6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-20 18:10:28--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28717126 (27M) [text/plain]\n",
            "Saving to: ‘answers_subsample.csv’\n",
            "\n",
            "answers_subsample.c 100%[===================>]  27.39M   108MB/s    in 0.3s    \n",
            "\n",
            "2021-12-20 18:10:29 (108 MB/s) - ‘answers_subsample.csv’ saved [28717126/28717126]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "Zjyyh_n6_fVg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('answers_subsample.csv')"
      ],
      "metadata": {
        "id": "VKoP50Yi_fSj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.category.value_counts() * 100 / data.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OCmDuIb_fQh",
        "outputId": "b9d8e2a2-0548-4798-a9c7-27b60d8d864f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "law         29.793211\n",
              "relax       22.016242\n",
              "business    19.309527\n",
              "food        18.367055\n",
              "love        10.513965\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "-m5RubAL_2Ys"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4sguXui_fJh",
        "outputId": "de707fc5-1b01-4550-ce7f-dce49545e143"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "TCZ6DGUMCKA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DMBdCGY_CpuH",
        "outputId": "5115c9f4-32c7-4544-8b80-c271f2defc8e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-71981d2a-fdcc-4cf3-b638-a321027e6044\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71981d2a-fdcc-4cf3-b638-a321027e6044')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71981d2a-fdcc-4cf3-b638-a321027e6044 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71981d2a-fdcc-4cf3-b638-a321027e6044');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   category                                               text\n",
              "0  business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1       law  Может ли срочник перевестись на контракт после...\n",
              "2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3  business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4       law                 часть 1 статья 158 похитил телефон"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "уменьшу данные"
      ],
      "metadata": {
        "id": "WZE3wKBDP43j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B9Nm6pWQHQm",
        "outputId": "06971e93-f8cc-4d43-92fe-b2263fe6b92f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "law         70842\n",
              "relax       52350\n",
              "business    45914\n",
              "food        43673\n",
              "love        25000\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cats = list(data['category'].unique())"
      ],
      "metadata": {
        "id": "GkxYiA29Qez4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRdljMZKQhfS",
        "outputId": "00c9f6f1-bb82-4504-c542-0e47b47947c4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['business', 'law', 'love', 'relax', 'food']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample"
      ],
      "metadata": {
        "id": "5yJjWT-AP7O0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_dfs = []"
      ],
      "metadata": {
        "id": "voBO6ycTP7L-"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cat in cats:\n",
        "  all_dfs.append(data[data['category'] == cat].sample(n=5000, random_state=42))\n",
        "\n",
        "newdf = pd.concat(all_dfs, axis=0, ignore_index=True)"
      ],
      "metadata": {
        "id": "fN9B7EtoP7JG"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdf['category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVUIXa2qQC0p",
        "outputId": "2991b0e4-4ce9-49fe-b38f-12ae010fe1d1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "law         5000\n",
              "business    5000\n",
              "relax       5000\n",
              "food        5000\n",
              "love        5000\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "k9w1oMQ8D3To"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(newdf.text, newdf.category, test_size=0.1)\n"
      ],
      "metadata": {
        "id": "22B9S6xiEe_A"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's extract the sentences and labels of our training set as numpy ndarrays.\n",
        "\n",
        "# Get the lists of sentences and their labels.\n",
        "sentences = list(x_train)\n",
        "labels = list(y_train)"
      ],
      "metadata": {
        "id": "13n6LmFWGIhK"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "labels = y_train.replace({'law':0, 'business':1, 'food':2, 'relax':3, 'love':4}).values"
      ],
      "metadata": {
        "id": "9UFurTRCINzH"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. BERT Tokenizer"
      ],
      "metadata": {
        "id": "yfTRUkNaGbtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp0hP7d4GWwC",
        "outputId": "77f087c1-de81-4cd3-f405-9b46fc0c03b7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Sentences to IDs"
      ],
      "metadata": {
        "id": "FmP_Ln-7GqGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8SMfK91GWuN",
        "outputId": "6d22a1af-b9ed-4913-bd85-74db63778a9c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  где заработать быткойнов?\n",
            "Token IDs: [101, 12472, 10242, 11136, 85905, 17686, 22889, 64243, 24508, 10634, 136, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Padding & Truncating"
      ],
      "metadata": {
        "id": "1nR9d66IGxjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "по графику распределения длин предложений из 1й тетрадки уже узвестно что надо паддить до 32"
      ],
      "metadata": {
        "id": "eX_ljYu5HJBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 32\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM1ZuCL1GWsT",
        "outputId": "fd9f1971-1ac3-455b-b5af-e8447fe66995"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 32 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4. Attention Masks"
      ],
      "metadata": {
        "id": "QEhgleuaHa2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "metadata": {
        "id": "EHZu0hAGHYpg"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5. Training & Validation Split"
      ],
      "metadata": {
        "id": "_rc1XF9sHhUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "metadata": {
        "id": "-TLNtr-3HYnj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6. Converting to PyTorch Data Types"
      ],
      "metadata": {
        "id": "QWymigdVHqnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEO88_rRH2c7",
        "outputId": "0ffdee71-63b4-4d3c-9682-86d977c853a9"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20250"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "metadata": {
        "id": "QzaiFNLtHYli"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "6_scApVrIeVI"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BertForSequenceClassification"
      ],
      "metadata": {
        "id": "Mu5WvkYhIs1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 5, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLuZTlkBHYfv",
        "outputId": "4dd99533-fe8f-461e-ab17-925e3f053b68"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = model.bert.pooler.dense.weight\n",
        "c = model.classifier.weight\n",
        "b = b.cpu().detach().numpy()\n",
        "c = c.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "-CbQIEwLHYZQ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaQWMg6JKgQz",
        "outputId": "b76416eb-5989-46ff-e5e2-b20f83daa405"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (105879, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ],
      "metadata": {
        "id": "hvL1vz1hKjBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "id": "4FSXqa5wKgJv"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 100, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "RwYjcXMYKgHX"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3. Training Loop"
      ],
      "metadata": {
        "id": "eS33cPpPKqIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "8d92I2LFKp4g"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "ApfKvJduKuil"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Pdynm6lYPN7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vpy10QvK3Z7",
        "outputId": "81e3be88-2dc0-4fcf-bdfa-e140cb0c2304"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    633.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    633.    Elapsed: 0:00:33.\n",
            "  Batch   120  of    633.    Elapsed: 0:00:49.\n",
            "  Batch   160  of    633.    Elapsed: 0:01:06.\n",
            "  Batch   200  of    633.    Elapsed: 0:01:22.\n",
            "  Batch   240  of    633.    Elapsed: 0:01:39.\n",
            "  Batch   280  of    633.    Elapsed: 0:01:55.\n",
            "  Batch   320  of    633.    Elapsed: 0:02:12.\n",
            "  Batch   360  of    633.    Elapsed: 0:02:29.\n",
            "  Batch   400  of    633.    Elapsed: 0:02:45.\n",
            "  Batch   440  of    633.    Elapsed: 0:03:02.\n",
            "  Batch   480  of    633.    Elapsed: 0:03:18.\n",
            "  Batch   520  of    633.    Elapsed: 0:03:35.\n",
            "  Batch   560  of    633.    Elapsed: 0:03:52.\n",
            "  Batch   600  of    633.    Elapsed: 0:04:08.\n",
            "\n",
            "  Average training loss: 0.83\n",
            "  Training epcoh took: 0:04:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation took: 0:00:08\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    633.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    633.    Elapsed: 0:00:33.\n",
            "  Batch   120  of    633.    Elapsed: 0:00:50.\n",
            "  Batch   160  of    633.    Elapsed: 0:01:06.\n",
            "  Batch   200  of    633.    Elapsed: 0:01:23.\n",
            "  Batch   240  of    633.    Elapsed: 0:01:39.\n",
            "  Batch   280  of    633.    Elapsed: 0:01:56.\n",
            "  Batch   320  of    633.    Elapsed: 0:02:13.\n",
            "  Batch   360  of    633.    Elapsed: 0:02:29.\n",
            "  Batch   400  of    633.    Elapsed: 0:02:46.\n",
            "  Batch   440  of    633.    Elapsed: 0:03:02.\n",
            "  Batch   480  of    633.    Elapsed: 0:03:19.\n",
            "  Batch   520  of    633.    Elapsed: 0:03:35.\n",
            "  Batch   560  of    633.    Elapsed: 0:03:52.\n",
            "  Batch   600  of    633.    Elapsed: 0:04:08.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:04:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:08\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    633.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    633.    Elapsed: 0:00:33.\n",
            "  Batch   120  of    633.    Elapsed: 0:00:50.\n",
            "  Batch   160  of    633.    Elapsed: 0:01:06.\n",
            "  Batch   200  of    633.    Elapsed: 0:01:23.\n",
            "  Batch   240  of    633.    Elapsed: 0:01:40.\n",
            "  Batch   280  of    633.    Elapsed: 0:01:56.\n",
            "  Batch   320  of    633.    Elapsed: 0:02:13.\n",
            "  Batch   360  of    633.    Elapsed: 0:02:29.\n",
            "  Batch   400  of    633.    Elapsed: 0:02:46.\n",
            "  Batch   440  of    633.    Elapsed: 0:03:02.\n",
            "  Batch   480  of    633.    Elapsed: 0:03:19.\n",
            "  Batch   520  of    633.    Elapsed: 0:03:36.\n",
            "  Batch   560  of    633.    Elapsed: 0:03:53.\n",
            "  Batch   600  of    633.    Elapsed: 0:04:10.\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Training epcoh took: 0:04:24\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:08\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    633.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    633.    Elapsed: 0:00:33.\n",
            "  Batch   120  of    633.    Elapsed: 0:00:50.\n",
            "  Batch   160  of    633.    Elapsed: 0:01:07.\n",
            "  Batch   200  of    633.    Elapsed: 0:01:23.\n",
            "  Batch   240  of    633.    Elapsed: 0:01:40.\n",
            "  Batch   280  of    633.    Elapsed: 0:01:57.\n",
            "  Batch   320  of    633.    Elapsed: 0:02:13.\n",
            "  Batch   360  of    633.    Elapsed: 0:02:30.\n",
            "  Batch   400  of    633.    Elapsed: 0:02:47.\n",
            "  Batch   440  of    633.    Elapsed: 0:03:03.\n",
            "  Batch   480  of    633.    Elapsed: 0:03:20.\n",
            "  Batch   520  of    633.    Elapsed: 0:03:36.\n",
            "  Batch   560  of    633.    Elapsed: 0:03:53.\n",
            "  Batch   600  of    633.    Elapsed: 0:04:10.\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epcoh took: 0:04:23\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:08\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3i8iZO3LLHZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## our training loss over all batches:"
      ],
      "metadata": {
        "id": "zg_PKa1TLaRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "pLSB67c4LHWu",
        "outputId": "b691a01e-edfa-4ea3-b6be-e225a9708c28"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Performance On val Set"
      ],
      "metadata": {
        "id": "Ta6xr1W6LdME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on val set\n",
        "\n",
        "print('Predicting labels for {:,} validation sentences...'.format(len(validation_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in validation_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "287CQU6CMByg",
        "outputId": "c5c18033-8d8a-496e-acff-a109c4e68a25"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 2,250 validation sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_targets = np.concatenate(true_labels).squeeze()\n",
        "\n",
        "predss = []\n",
        "for el in predictions:\n",
        "  predss.append(np.argmax(el, axis=1))\n",
        "\n",
        "test_pred_class = np.concatenate(predss).squeeze()\n",
        "\n",
        "f1 = f1_score(test_targets, test_pred_class, average='micro')"
      ],
      "metadata": {
        "id": "TGlAeGDEXbCX"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIvoZqvcYVBx",
        "outputId": "01ece752-773e-49ea-baa6-bc78176fba8e"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8235555555555556"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "вроде бы сравнимый результат"
      ],
      "metadata": {
        "id": "dnRibgU_YeJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LqDLOh43Xa-9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}